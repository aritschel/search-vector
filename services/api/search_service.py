from fastapi import FastAPI, HTTPException, Query
from services.database.db_manager import DBManager
from utils.embedding_processor import EmbeddingProcessor
from langchain_postgres.vectorstores import PGVector
from services.utils.llm_manager import LLMManager

app = FastAPI()
db = DBManager()
embeddings = EmbeddingProcessor()
vectorstore = PGVector(
    collection_name="documents", embeddings=embeddings.model, connection=db.conn_string
)
llm_manager = LLMManager()


@app.get("/search")
def search_documents(question: str = Query(), k: int = 3):
    """
    Search for documents similar to the question and generate a response using LLM.

    Args:
        question (str): The search question.
        k (int): The number of top similar documents to fetch.

    Returns:
        str: The response generated by the LLM based on the search results.

    Raises:
        HTTPException: If there is an error during the search or LLM response generation.
    """
    try:
        embedding = embeddings.generate_embedding(question)
        results = db.fetch_similar_documents(embedding, top_k=k)

        if not results:
            return ""

        documents = "\n".join(row[0] for row in results if row[0])

        try:
            response = llm_manager.generate_response(question, documents)
        except Exception as llm_error:
            raise HTTPException(
                status_code=503, detail=f"Erro ao chamar LLM: {str(llm_error)}"
            )
        return response

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
